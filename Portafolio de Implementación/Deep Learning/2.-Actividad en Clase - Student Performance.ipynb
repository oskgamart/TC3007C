{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are a data scientist working for a school\n",
    "\n",
    "You are asked to predict the GPA of the current students based on the following provided data: \n",
    "\n",
    " 0   StudentID  int64  \n",
    " 1   Age    int64  \n",
    " 2   Gender int64  \n",
    " 3   Ethnicity  int64  \n",
    " 4   ParentalEducation  int64  \n",
    " 5   StudyTimeWeekly    float64\n",
    " 6   Absences   int64  \n",
    " 7   Tutoring   int64  \n",
    " 8   ParentalSupport    int64  \n",
    " 9   Extracurricular    int64  \n",
    " 10  Sports int64  \n",
    " 11  Music  int64  \n",
    " 12  Volunteering   int64  \n",
    " 13  GPA    float64\n",
    " 14  GradeClass float64\n",
    "\n",
    "The GPA is the Grade Point Average, typically ranges from 0.0 to 4.0 in most educational systems, with 4.0 representing an 'A' or excellent performance.\n",
    "\n",
    "The minimum passing GPA can vary by institution, but it's often around 2.0. This usually corresponds to a 'C' grade, which is considered satisfactory.\n",
    "\n",
    "You need to create a Deep Learning model capable to predict the GPA of a Student based on a set of provided features.\n",
    "The data provided represents 2,392 students.\n",
    "\n",
    "In this excersice you will be requested to create a total of three models and select the most performant one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries\n",
    "\n",
    "First let's import the following libraries, if there is any library that you need and is not in the list bellow feel free to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Data\n",
    "\n",
    "- You will be provided with a cvs (comma separated value) file.\n",
    "- You will need to add that file into a pandas dataframe, you can use the following code as reference\n",
    "- The file will be available in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3388</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.680555</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.455509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3389</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.583217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.279150</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3390</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.805500</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3391</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.416653</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3392</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.819907</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0          1001   17       1          0                  2        19.833723   \n",
       "1          1002   18       0          0                  1        15.408756   \n",
       "2          1003   15       0          2                  3         4.210570   \n",
       "3          1004   17       1          0                  3        10.028829   \n",
       "4          1005   17       1          0                  2         4.672495   \n",
       "...         ...  ...     ...        ...                ...              ...   \n",
       "2387       3388   18       1          0                  3        10.680555   \n",
       "2388       3389   17       0          0                  1         7.583217   \n",
       "2389       3390   16       1          0                  2         6.805500   \n",
       "2390       3391   16       1          1                  0        12.416653   \n",
       "2391       3392   16       1          0                  2        17.819907   \n",
       "\n",
       "      Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0            7         1                2                0       0      1   \n",
       "1            0         0                1                0       0      0   \n",
       "2           26         0                2                0       0      0   \n",
       "3           14         0                3                1       0      0   \n",
       "4           17         1                3                0       0      0   \n",
       "...        ...       ...              ...              ...     ...    ...   \n",
       "2387         2         0                4                1       0      0   \n",
       "2388         4         1                4                0       1      0   \n",
       "2389        20         0                2                0       0      0   \n",
       "2390        17         0                2                0       1      1   \n",
       "2391        13         0                2                0       0      0   \n",
       "\n",
       "      Volunteering       GPA  GradeClass  \n",
       "0                0  2.929196         2.0  \n",
       "1                0  3.042915         1.0  \n",
       "2                0  0.112602         4.0  \n",
       "3                0  2.054218         3.0  \n",
       "4                0  1.288061         4.0  \n",
       "...            ...       ...         ...  \n",
       "2387             0  3.455509         0.0  \n",
       "2388             0  3.279150         4.0  \n",
       "2389             1  1.142333         2.0  \n",
       "2390             0  1.803297         1.0  \n",
       "2391             1  2.140014         1.0  \n",
       "\n",
       "[2392 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Student_performance_data _.csv\")\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Review you data:\n",
    "\n",
    "Make sure you review your data.\n",
    "Place special attention of null or empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   StudentID          2392 non-null   int64  \n",
      " 1   Age                2392 non-null   int64  \n",
      " 2   Gender             2392 non-null   int64  \n",
      " 3   Ethnicity          2392 non-null   int64  \n",
      " 4   ParentalEducation  2392 non-null   int64  \n",
      " 5   StudyTimeWeekly    2392 non-null   float64\n",
      " 6   Absences           2392 non-null   int64  \n",
      " 7   Tutoring           2392 non-null   int64  \n",
      " 8   ParentalSupport    2392 non-null   int64  \n",
      " 9   Extracurricular    2392 non-null   int64  \n",
      " 10  Sports             2392 non-null   int64  \n",
      " 11  Music              2392 non-null   int64  \n",
      " 12  Volunteering       2392 non-null   int64  \n",
      " 13  GPA                2392 non-null   float64\n",
      " 14  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 280.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the columns not needed for Student performance prediction\n",
    "\n",
    "- Choose only the columns you consider to be valuable for your model training.\n",
    "- For example, StudentID might not be a good feature for your model, and thus should be removed from your main dataset, which other columns should also be removed?\n",
    "- You can name that final dataset as 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "dataset = data.drop(columns=[\"StudentID\",\"Gender\",\"Ethnicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check if the columns has any null values:\n",
    "- Here you now have your final dataset to use in your model training.\n",
    "- Before moving foward review your data check for any null or empty value that might be needed to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                  0\n",
      "ParentalEducation    0\n",
      "StudyTimeWeekly      0\n",
      "Absences             0\n",
      "Tutoring             0\n",
      "ParentalSupport      0\n",
      "Extracurricular      0\n",
      "Sports               0\n",
      "Music                0\n",
      "Volunteering         0\n",
      "GPA                  0\n",
      "GradeClass           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare your data for training and for testing set:\n",
    " - First create a dataset named X, with all columns but GPA. These are the features\n",
    " - Next create another dataset named y, with only GPA column. This is the label\n",
    " - If you go to your Imports, you will see the following import: **'from sklearn.model_selection import train_test_split'**\n",
    " - Use that *train_test_split* function to create: X_train, X_test, y_train and y_test respectively. Use X and y datasets as parameters. Other parameters to use are: Test Size = 0.2, Random State = 42.\n",
    " \n",
    " - Standarize your features (X_train and X_test) by using the StandardScaler (investigate how to use fit_transform and transform functions). This will help the training process by dealing with normilized data.\n",
    "\n",
    " Note: Your X_train shape should be around (1913, 10). This means the dataset has 10 columns which should be the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "X = dataset.drop(columns=['GPA'])\n",
    "y = dataset['GPA']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define your Deep Neural Network.\n",
    "- This will be a Sequential Neural Network.\n",
    "- With a Dense input layer with 64 units, and input dimention of 10 and Relu as the activation function.\n",
    "- A Dense hidden layer with 32 units, and Relu as the activation function.\n",
    "- And a Dense output layer with 1 unit, do not define an activation function so it defaults to linear, suitable for regression tasks. e.g. Dense(1)\n",
    "\n",
    "This last part of the output layer is super important, since we want to predict the GPA, this means that we want a regression and not a classification. Linear activation function is best for regression and Sigmoid is best for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),                            \n",
    "    Dense(1)                  \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile your Neural Network\n",
    "- Choose Adam as the optimizer\n",
    "- And MSE as the Loss function\n",
    "- Also add the following metrics: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse', \n",
    "    metrics=['mae']  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit (or train) your model\n",
    "- Use the X_train and y_train datasets for the training\n",
    "- Do 50 data iterations\n",
    "- Choose the batch size = 10\n",
    "- Also select a validation_split of 0.2\n",
    "- Save the result of the fit function in a variable called 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8086 - mae: 1.0416 - val_loss: 0.1543 - val_mae: 0.3153\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1277 - mae: 0.2846 - val_loss: 0.0830 - val_mae: 0.2330\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0737 - mae: 0.2143 - val_loss: 0.0675 - val_mae: 0.2063\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0601 - mae: 0.1940 - val_loss: 0.0571 - val_mae: 0.1919\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0534 - mae: 0.1850 - val_loss: 0.0517 - val_mae: 0.1814\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0438 - mae: 0.1668 - val_loss: 0.0474 - val_mae: 0.1747\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mae: 0.1676 - val_loss: 0.0477 - val_mae: 0.1772\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - mae: 0.1583 - val_loss: 0.0524 - val_mae: 0.1852\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1622 - val_loss: 0.0628 - val_mae: 0.1988\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0361 - mae: 0.1505 - val_loss: 0.0431 - val_mae: 0.1667\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.1503 - val_loss: 0.0457 - val_mae: 0.1693\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0325 - mae: 0.1461 - val_loss: 0.0437 - val_mae: 0.1661\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0312 - mae: 0.1404 - val_loss: 0.0447 - val_mae: 0.1690\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0301 - mae: 0.1375 - val_loss: 0.0429 - val_mae: 0.1638\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0320 - mae: 0.1442 - val_loss: 0.0421 - val_mae: 0.1624\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0320 - mae: 0.1434 - val_loss: 0.0421 - val_mae: 0.1642\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0316 - mae: 0.1428 - val_loss: 0.0420 - val_mae: 0.1604\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0283 - mae: 0.1332 - val_loss: 0.0421 - val_mae: 0.1637\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0297 - mae: 0.1365 - val_loss: 0.0406 - val_mae: 0.1603\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - mae: 0.1331 - val_loss: 0.0439 - val_mae: 0.1653\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0259 - mae: 0.1277 - val_loss: 0.0421 - val_mae: 0.1618\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0267 - mae: 0.1282 - val_loss: 0.0431 - val_mae: 0.1627\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0258 - mae: 0.1299 - val_loss: 0.0435 - val_mae: 0.1639\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - mae: 0.1280 - val_loss: 0.0420 - val_mae: 0.1608\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0247 - mae: 0.1246 - val_loss: 0.0417 - val_mae: 0.1603\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0250 - mae: 0.1270 - val_loss: 0.0433 - val_mae: 0.1629\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0274 - mae: 0.1302 - val_loss: 0.0425 - val_mae: 0.1610\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0251 - mae: 0.1247 - val_loss: 0.0459 - val_mae: 0.1659\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0242 - mae: 0.1239 - val_loss: 0.0436 - val_mae: 0.1619\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0243 - mae: 0.1228 - val_loss: 0.0418 - val_mae: 0.1606\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0227 - mae: 0.1189 - val_loss: 0.0440 - val_mae: 0.1629\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0217 - mae: 0.1153 - val_loss: 0.0441 - val_mae: 0.1628\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0237 - mae: 0.1220 - val_loss: 0.0472 - val_mae: 0.1705\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0228 - mae: 0.1178 - val_loss: 0.0423 - val_mae: 0.1585\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - mae: 0.1181 - val_loss: 0.0433 - val_mae: 0.1627\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0199 - mae: 0.1132 - val_loss: 0.0432 - val_mae: 0.1617\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mae: 0.1116 - val_loss: 0.0452 - val_mae: 0.1629\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0201 - mae: 0.1125 - val_loss: 0.0472 - val_mae: 0.1672\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0223 - mae: 0.1180 - val_loss: 0.0452 - val_mae: 0.1655\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0206 - mae: 0.1129 - val_loss: 0.0464 - val_mae: 0.1682\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0194 - mae: 0.1109 - val_loss: 0.0436 - val_mae: 0.1623\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0197 - mae: 0.1125 - val_loss: 0.0491 - val_mae: 0.1724\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0212 - mae: 0.1149 - val_loss: 0.0439 - val_mae: 0.1640\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mae: 0.1086 - val_loss: 0.0444 - val_mae: 0.1625\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0179 - mae: 0.1081 - val_loss: 0.0425 - val_mae: 0.1619\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0189 - mae: 0.1077 - val_loss: 0.0458 - val_mae: 0.1665\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0183 - mae: 0.1083 - val_loss: 0.0459 - val_mae: 0.1671\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0185 - mae: 0.1067 - val_loss: 0.0454 - val_mae: 0.1679\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180 - mae: 0.1060 - val_loss: 0.0452 - val_mae: 0.1646\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - mae: 0.1100 - val_loss: 0.0468 - val_mae: 0.1668\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. View your history variable:\n",
    "- Use Matplotlib.pyplot to show graphs of your model traning history\n",
    "- In one graph:\n",
    "   - Plot the Training Loss and the Validation Loss\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Loss\n",
    "   - Title = Training and Validation Loss over Epochs\n",
    "- In a second graph:\n",
    "   - Plot the Training MAE and the Validation MAE\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Mean Absolute Error (MAE)\n",
    "   - Title = Training and Validation MAE over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history_df['loss'], label='Train Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_df['mae'], label='Train Loss')\n",
    "plt.plot(history_df['val_mae'], label='Validation Loss')\n",
    "plt.title('Training and Validation MAE over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your model:\n",
    "- See the result of your loss function.\n",
    "- What can you deduct from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0512 - mae: 0.1772\n",
      "loss 0.04827618971467018\n",
      "mae 0.17272977530956268\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"loss\", loss)\n",
    "print(\"mae\", mae)\n",
    "#print(\"mae\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use your model to make some predictions:\n",
    "- Make predictions of your X_test dataset\n",
    "- Print the each of the predictions and the actual value (which is in y_test)\n",
    "- How good was your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Prediction: 1.385005235671997 Actual: 1.4277243762746905\n",
      "Prediction: 2.952120065689087 Actual: 3.117354434785501\n",
      "Prediction: 1.8438036441802979 Actual: 2.037768574636005\n",
      "Prediction: 3.620173931121826 Actual: 3.5485205508668662\n",
      "Prediction: 0.3166281580924988 Actual: 0.2489771312307257\n",
      "Prediction: 2.836190938949585 Actual: 2.627693905554347\n",
      "Prediction: 1.6215415000915527 Actual: 2.057378500596372\n",
      "Prediction: 2.3650319576263428 Actual: 2.248337588471201\n",
      "Prediction: 2.2245020866394043 Actual: 2.1947065208246226\n",
      "Prediction: 1.005683183670044 Actual: 0.7581829737450007\n",
      "Prediction: 2.718135356903076 Actual: 2.370893096932428\n",
      "Prediction: 0.664585530757904 Actual: 0.7664048694920337\n",
      "Prediction: 2.9960856437683105 Actual: 2.952721567213245\n",
      "Prediction: 2.7815756797790527 Actual: 2.3433313526833226\n",
      "Prediction: 2.6253151893615723 Actual: 2.7718106588704914\n",
      "Prediction: 0.3557092249393463 Actual: 0.2878673233291232\n",
      "Prediction: 1.1680123805999756 Actual: 1.0182646498699195\n",
      "Prediction: 1.4649934768676758 Actual: 1.629355895809393\n",
      "Prediction: 1.966001272201538 Actual: 2.0744387503601613\n",
      "Prediction: 2.131077289581299 Actual: 2.423800751639832\n",
      "Prediction: 2.1056931018829346 Actual: 1.7562115530004156\n",
      "Prediction: 1.6669776439666748 Actual: 1.5662885180613493\n",
      "Prediction: 1.6567144393920898 Actual: 1.7062124885863237\n",
      "Prediction: 3.0119075775146484 Actual: 3.161436270258364\n",
      "Prediction: 1.5389277935028076 Actual: 1.733364046560005\n",
      "Prediction: 0.6165448427200317 Actual: 0.8419632253726905\n",
      "Prediction: 1.664088249206543 Actual: 1.3791671997209602\n",
      "Prediction: 2.6212551593780518 Actual: 3.026983310961493\n",
      "Prediction: 2.3918018341064453 Actual: 2.191998419606377\n",
      "Prediction: 1.7879304885864258 Actual: 2.315769874969324\n",
      "Prediction: 2.024625062942505 Actual: 2.068111784968204\n",
      "Prediction: 0.5765500664710999 Actual: 0.869123386308555\n",
      "Prediction: 2.9913454055786133 Actual: 2.900096239205548\n",
      "Prediction: 3.2996561527252197 Actual: 3.468581349135728\n",
      "Prediction: 1.503937005996704 Actual: 1.5674124377048069\n",
      "Prediction: 1.7531273365020752 Actual: 1.7946671055341392\n",
      "Prediction: 3.251605272293091 Actual: 3.1813076022771107\n",
      "Prediction: 2.8553829193115234 Actual: 2.8973550040674096\n",
      "Prediction: 3.2527220249176025 Actual: 3.2448822032661777\n",
      "Prediction: 0.7463694214820862 Actual: 0.3578088919508027\n",
      "Prediction: 2.39115309715271 Actual: 2.6523548127186087\n",
      "Prediction: 3.639526844024658 Actual: 3.680961344427839\n",
      "Prediction: 1.30409836769104 Actual: 1.0363787383257312\n",
      "Prediction: 2.1070644855499268 Actual: 2.017218038843316\n",
      "Prediction: 0.915407121181488 Actual: 0.9633750092514732\n",
      "Prediction: 2.480612277984619 Actual: 2.23946398594873\n",
      "Prediction: 2.733816623687744 Actual: 2.735960967147571\n",
      "Prediction: 1.0203948020935059 Actual: 1.3619328272119078\n",
      "Prediction: 2.9257168769836426 Actual: 2.70295861751592\n",
      "Prediction: 1.4713077545166016 Actual: 1.441918756451196\n",
      "Prediction: 3.115858316421509 Actual: 3.219531247903172\n",
      "Prediction: 3.199738025665283 Actual: 3.339094362200312\n",
      "Prediction: 1.368699073791504 Actual: 1.556218796080208\n",
      "Prediction: 1.113236904144287 Actual: 1.3423871779577343\n",
      "Prediction: 1.9489259719848633 Actual: 1.756186167808898\n",
      "Prediction: 3.228334903717041 Actual: 3.421837670026282\n",
      "Prediction: 2.5831212997436523 Actual: 2.3169599744650875\n",
      "Prediction: 3.445124626159668 Actual: 3.286585133610396\n",
      "Prediction: 1.1666476726531982 Actual: 0.684651926072042\n",
      "Prediction: 1.9913249015808105 Actual: 2.1370681063433614\n",
      "Prediction: 1.7284250259399414 Actual: 1.6884896091579062\n",
      "Prediction: 1.5112769603729248 Actual: 2.1962173498725552\n",
      "Prediction: 2.243272304534912 Actual: 2.4777903742896354\n",
      "Prediction: 1.537449598312378 Actual: 1.1979333311054492\n",
      "Prediction: 0.8468610644340515 Actual: 0.9881530769380218\n",
      "Prediction: 1.9776887893676758 Actual: 1.8589248556209292\n",
      "Prediction: 2.9046061038970947 Actual: 3.040729612939948\n",
      "Prediction: 2.445199966430664 Actual: 2.3741309720150148\n",
      "Prediction: 0.9836114048957825 Actual: 1.2212994205081906\n",
      "Prediction: 3.3174681663513184 Actual: 3.2742334588098787\n",
      "Prediction: 3.3852577209472656 Actual: 3.5451594318003106\n",
      "Prediction: 0.9272581934928894 Actual: 1.101939932271634\n",
      "Prediction: 3.00730037689209 Actual: 2.968807133269986\n",
      "Prediction: 2.5098700523376465 Actual: 2.5761746968185832\n",
      "Prediction: 0.9466647505760193 Actual: 0.4541144380742554\n",
      "Prediction: 2.6867823600769043 Actual: 2.6741625507699083\n",
      "Prediction: 2.0174129009246826 Actual: 2.05996665628182\n",
      "Prediction: 1.691986083984375 Actual: 1.983133992222757\n",
      "Prediction: 0.1630614548921585 Actual: 0.2123670952038988\n",
      "Prediction: 1.1990320682525635 Actual: 1.279370611476852\n",
      "Prediction: 1.9813525676727295 Actual: 2.029736582447598\n",
      "Prediction: 2.674499273300171 Actual: 3.189217169770364\n",
      "Prediction: 2.1950814723968506 Actual: 2.2564883117007817\n",
      "Prediction: 1.6577765941619873 Actual: 1.636403110402885\n",
      "Prediction: 1.452735185623169 Actual: 1.4015509339508203\n",
      "Prediction: 0.6632674336433411 Actual: 0.4436406552124723\n",
      "Prediction: 3.75661563873291 Actual: 4.0\n",
      "Prediction: 0.9565654397010803 Actual: 1.2712295298373406\n",
      "Prediction: 1.3381202220916748 Actual: 1.3026414038177534\n",
      "Prediction: 1.7493596076965332 Actual: 1.5970165723817666\n",
      "Prediction: 2.6834826469421387 Actual: 2.5353912836886785\n",
      "Prediction: 1.3234248161315918 Actual: 1.382935704905427\n",
      "Prediction: 0.9531265497207642 Actual: 1.0384883524708666\n",
      "Prediction: 0.6595037579536438 Actual: 0.1306542378736745\n",
      "Prediction: 1.7476539611816406 Actual: 1.2738181762310288\n",
      "Prediction: 1.2674589157104492 Actual: 1.2714946229661936\n",
      "Prediction: 3.4782586097717285 Actual: 3.3250668431789085\n",
      "Prediction: 0.9734223484992981 Actual: 1.0707079518820537\n",
      "Prediction: 1.5863783359527588 Actual: 1.574306088258861\n",
      "Prediction: 1.5799717903137207 Actual: 1.6336793710032238\n",
      "Prediction: 0.23101820051670074 Actual: 0.0\n",
      "Prediction: 2.2705564498901367 Actual: 2.122102757166825\n",
      "Prediction: 1.2223286628723145 Actual: 1.2912304259430896\n",
      "Prediction: 1.6414885520935059 Actual: 1.4547228982036302\n",
      "Prediction: 0.8180565237998962 Actual: 0.7742848136453381\n",
      "Prediction: 2.2242774963378906 Actual: 2.293087191388992\n",
      "Prediction: 2.739694118499756 Actual: 2.6827762879633723\n",
      "Prediction: 1.219801664352417 Actual: 1.3154643711031746\n",
      "Prediction: 1.3814942836761475 Actual: 1.4693892718306072\n",
      "Prediction: 0.6955924034118652 Actual: 0.61316598823277\n",
      "Prediction: 1.5719630718231201 Actual: 1.8819787410279116\n",
      "Prediction: 2.0899839401245117 Actual: 2.268905391743987\n",
      "Prediction: 2.987492322921753 Actual: 3.545153035874012\n",
      "Prediction: 0.5826973915100098 Actual: 0.4258137609932144\n",
      "Prediction: 0.4826904535293579 Actual: 0.5403751565523403\n",
      "Prediction: 1.2469875812530518 Actual: 1.1110684623439582\n",
      "Prediction: 1.7520196437835693 Actual: 2.035367286041147\n",
      "Prediction: 2.5398192405700684 Actual: 2.995458295719109\n",
      "Prediction: 0.8036715388298035 Actual: 1.2178731513333656\n",
      "Prediction: 1.9246134757995605 Actual: 2.1269889706667486\n",
      "Prediction: 0.819144070148468 Actual: 0.5297986094952745\n",
      "Prediction: 3.277202606201172 Actual: 3.0168978681026624\n",
      "Prediction: 3.4135329723358154 Actual: 3.5921289778598062\n",
      "Prediction: 0.9741580486297607 Actual: 1.0583113523259429\n",
      "Prediction: 1.8613555431365967 Actual: 1.8425841347566336\n",
      "Prediction: 1.0046547651290894 Actual: 1.254572618142762\n",
      "Prediction: 2.6281423568725586 Actual: 2.794885282534225\n",
      "Prediction: 0.9330539107322693 Actual: 1.3478638291935137\n",
      "Prediction: 2.047524929046631 Actual: 2.226983393791037\n",
      "Prediction: 2.840061664581299 Actual: 2.81347034515229\n",
      "Prediction: 1.0729128122329712 Actual: 1.1055870981431069\n",
      "Prediction: 3.4895691871643066 Actual: 4.0\n",
      "Prediction: 2.8116073608398438 Actual: 2.898151345753362\n",
      "Prediction: 0.3516876995563507 Actual: 0.4239919484053893\n",
      "Prediction: 0.39472469687461853 Actual: 0.691477418739295\n",
      "Prediction: 0.6975448131561279 Actual: 0.930028645913522\n",
      "Prediction: 2.0322718620300293 Actual: 2.330783482945125\n",
      "Prediction: -0.003968745470046997 Actual: 0.3375541414467983\n",
      "Prediction: 0.24828580021858215 Actual: 0.5022261210258885\n",
      "Prediction: 1.0490715503692627 Actual: 0.9893299205987556\n",
      "Prediction: 2.6249518394470215 Actual: 2.745858798383193\n",
      "Prediction: 1.5875744819641113 Actual: 1.8041546917762192\n",
      "Prediction: 3.0799643993377686 Actual: 3.3432781941994127\n",
      "Prediction: 1.4326529502868652 Actual: 1.5730510214028783\n",
      "Prediction: 2.70117449760437 Actual: 2.964009263152522\n",
      "Prediction: 1.2298133373260498 Actual: 1.1936177713396423\n",
      "Prediction: 1.3635683059692383 Actual: 1.3492561219436314\n",
      "Prediction: 2.38897442817688 Actual: 2.520175258554297\n",
      "Prediction: 2.625825881958008 Actual: 3.2537859623175915\n",
      "Prediction: 1.3922810554504395 Actual: 1.4633796485356\n",
      "Prediction: 3.177375316619873 Actual: 3.161961511352394\n",
      "Prediction: 0.7895177006721497 Actual: 0.7696361214560695\n",
      "Prediction: 3.332690715789795 Actual: 3.5037432645192648\n",
      "Prediction: 1.3586902618408203 Actual: 1.2687721230682183\n",
      "Prediction: 0.9063274264335632 Actual: 1.1708122846030742\n",
      "Prediction: 0.4688694477081299 Actual: 0.4712831088434319\n",
      "Prediction: 1.342275619506836 Actual: 1.3978971899557189\n",
      "Prediction: 0.6570731997489929 Actual: 0.9689861311254953\n",
      "Prediction: 1.4503002166748047 Actual: 1.511276997165948\n",
      "Prediction: 0.4259803295135498 Actual: 0.5242135665585334\n",
      "Prediction: 1.4337201118469238 Actual: 1.4913821292254057\n",
      "Prediction: 1.3186237812042236 Actual: 1.519441725815139\n",
      "Prediction: 0.826753556728363 Actual: 0.7132676650608875\n",
      "Prediction: 0.6147569417953491 Actual: 0.4005694786322673\n",
      "Prediction: 0.22771893441677094 Actual: 0.5813557994949716\n",
      "Prediction: 0.41075775027275085 Actual: 0.4050526130408124\n",
      "Prediction: 0.7294195890426636 Actual: 1.1544100089135072\n",
      "Prediction: 1.18796706199646 Actual: 1.150153548429549\n",
      "Prediction: 2.221935749053955 Actual: 2.45790140704778\n",
      "Prediction: 3.703073024749756 Actual: 3.4555094110343934\n",
      "Prediction: 1.4790856838226318 Actual: 1.4414095429135232\n",
      "Prediction: 3.4260969161987305 Actual: 3.2879731984208025\n",
      "Prediction: 2.9521267414093018 Actual: 3.043931624402609\n",
      "Prediction: 0.9233844876289368 Actual: 0.189818059909026\n",
      "Prediction: 1.2329237461090088 Actual: 1.1657871621526066\n",
      "Prediction: 2.3034353256225586 Actual: 2.565368052695248\n",
      "Prediction: 2.177744150161743 Actual: 2.2346855491679\n",
      "Prediction: 1.074958086013794 Actual: 1.25865485443205\n",
      "Prediction: 2.1757543087005615 Actual: 2.116723382234456\n",
      "Prediction: 1.402482509613037 Actual: 1.674676218445066\n",
      "Prediction: 2.751343250274658 Actual: 2.8211081074612654\n",
      "Prediction: 1.5658485889434814 Actual: 1.9961073864422316\n",
      "Prediction: 0.7554033994674683 Actual: 0.8090678531539729\n",
      "Prediction: 2.96525502204895 Actual: 2.546634577748015\n",
      "Prediction: 3.2846460342407227 Actual: 2.735041610764964\n",
      "Prediction: 2.93381404876709 Actual: 2.7535902317989964\n",
      "Prediction: 3.3497231006622314 Actual: 3.283916521897384\n",
      "Prediction: 1.4659953117370605 Actual: 1.2878189977208636\n",
      "Prediction: 0.3326156735420227 Actual: 0.3106695325979863\n",
      "Prediction: 1.7597706317901611 Actual: 1.83151128144078\n",
      "Prediction: 1.2184348106384277 Actual: 0.911568270646688\n",
      "Prediction: 1.9440333843231201 Actual: 2.109686328016939\n",
      "Prediction: 1.422353982925415 Actual: 1.0444999950877136\n",
      "Prediction: 0.7489869594573975 Actual: 0.9654824453045304\n",
      "Prediction: 1.6878001689910889 Actual: 1.5504493308923313\n",
      "Prediction: 1.0109927654266357 Actual: 1.223828264622006\n",
      "Prediction: 1.6069812774658203 Actual: 1.8934409155419147\n",
      "Prediction: 1.8823919296264648 Actual: 2.295362280360723\n",
      "Prediction: 2.788438081741333 Actual: 2.8393132491560324\n",
      "Prediction: 2.2990736961364746 Actual: 2.251847104187132\n",
      "Prediction: 1.5513358116149902 Actual: 1.4053156279015715\n",
      "Prediction: 3.0085256099700928 Actual: 3.03210533252155\n",
      "Prediction: 0.3881073594093323 Actual: 0.5694198849254213\n",
      "Prediction: 2.1215882301330566 Actual: 2.220050546998637\n",
      "Prediction: 2.777574062347412 Actual: 2.7373779261627598\n",
      "Prediction: 1.9907920360565186 Actual: 2.340811012860678\n",
      "Prediction: 0.23109549283981323 Actual: 0.5601746057023475\n",
      "Prediction: 2.846623420715332 Actual: 2.913887649138132\n",
      "Prediction: 2.2140462398529053 Actual: 2.259451153743707\n",
      "Prediction: 1.516284704208374 Actual: 1.7419681672894356\n",
      "Prediction: 1.5353224277496338 Actual: 1.2658914451513914\n",
      "Prediction: 1.015549898147583 Actual: 1.298729106820987\n",
      "Prediction: 1.9039967060089111 Actual: 1.9137997969013387\n",
      "Prediction: 2.618739366531372 Actual: 2.7808169956104924\n",
      "Prediction: 2.6311426162719727 Actual: 2.553484846074773\n",
      "Prediction: 0.732849657535553 Actual: 0.8922661351679123\n",
      "Prediction: 2.7081480026245117 Actual: 2.669749932596335\n",
      "Prediction: 3.1549906730651855 Actual: 3.088512305616677\n",
      "Prediction: 1.6359426975250244 Actual: 1.5635740338353443\n",
      "Prediction: 2.8684310913085938 Actual: 2.875735286006944\n",
      "Prediction: 0.5605458617210388 Actual: 1.184519764401664\n",
      "Prediction: 2.5787715911865234 Actual: 2.584174278596964\n",
      "Prediction: 3.7357304096221924 Actual: 3.812757187598897\n",
      "Prediction: 0.4433891177177429 Actual: 0.6729361977994386\n",
      "Prediction: 1.556197166442871 Actual: 1.9558725265628367\n",
      "Prediction: 1.6508853435516357 Actual: 1.773293697386631\n",
      "Prediction: 3.0140795707702637 Actual: 3.055386295398076\n",
      "Prediction: 2.804715394973755 Actual: 2.718465435794503\n",
      "Prediction: 1.3578929901123047 Actual: 1.2705295622953123\n",
      "Prediction: 1.8548529148101807 Actual: 1.9879647265294176\n",
      "Prediction: 1.4987962245941162 Actual: 1.7209071500753406\n",
      "Prediction: 2.0530219078063965 Actual: 2.1105837595046006\n",
      "Prediction: 2.861753225326538 Actual: 2.8816123214605245\n",
      "Prediction: 0.9691051244735718 Actual: 0.9707643470928292\n",
      "Prediction: 2.917053699493408 Actual: 2.9728834414945147\n",
      "Prediction: 2.7205281257629395 Actual: 2.5210277348652257\n",
      "Prediction: 0.39100727438926697 Actual: 0.5152393995715008\n",
      "Prediction: 1.1996259689331055 Actual: 1.0085719028530793\n",
      "Prediction: 2.7428107261657715 Actual: 2.791339403107066\n",
      "Prediction: 0.7753281593322754 Actual: 0.586837405483887\n",
      "Prediction: 3.504240036010742 Actual: 3.666290826527483\n",
      "Prediction: 0.846244215965271 Actual: 0.9030855768578068\n",
      "Prediction: 0.5450028777122498 Actual: 0.7045952434646587\n",
      "Prediction: 2.3476486206054688 Actual: 2.3983144793001743\n",
      "Prediction: 1.5031521320343018 Actual: 1.817789572439356\n",
      "Prediction: 0.605746328830719 Actual: 0.7995911976901089\n",
      "Prediction: 2.297783136367798 Actual: 2.127408865912826\n",
      "Prediction: 0.9644529223442078 Actual: 1.1767815056705988\n",
      "Prediction: 0.5110068321228027 Actual: 0.4291372796949342\n",
      "Prediction: 2.0710716247558594 Actual: 2.0469388171096283\n",
      "Prediction: 1.0419273376464844 Actual: 1.0861513973549914\n",
      "Prediction: 2.7943928241729736 Actual: 2.9869427371126283\n",
      "Prediction: 2.5040395259857178 Actual: 2.474039536809681\n",
      "Prediction: 1.8579654693603516 Actual: 1.581931480635446\n",
      "Prediction: 2.1826508045196533 Actual: 2.3278327626806856\n",
      "Prediction: 1.9346859455108643 Actual: 1.5252820489261911\n",
      "Prediction: 1.3897631168365479 Actual: 1.6831172628416484\n",
      "Prediction: 2.4080588817596436 Actual: 2.4610469629080955\n",
      "Prediction: 0.10358700156211853 Actual: 0.0278186247324679\n",
      "Prediction: 1.4187953472137451 Actual: 1.5364194793970165\n",
      "Prediction: 1.9728994369506836 Actual: 2.0998851567205854\n",
      "Prediction: 0.45378977060317993 Actual: 0.3751478505639292\n",
      "Prediction: 1.5053496360778809 Actual: 1.2945928801079334\n",
      "Prediction: 0.6480111479759216 Actual: 0.7697406121390962\n",
      "Prediction: 1.7635407447814941 Actual: 1.821442173929074\n",
      "Prediction: 3.236750841140747 Actual: 3.4982573417733205\n",
      "Prediction: 2.312452793121338 Actual: 2.378050042081803\n",
      "Prediction: 0.6482275724411011 Actual: 0.5185224297099189\n",
      "Prediction: 2.6341888904571533 Actual: 2.754877493270432\n",
      "Prediction: 2.1070315837860107 Actual: 2.207001981395421\n",
      "Prediction: 1.1805953979492188 Actual: 1.1416385674703\n",
      "Prediction: 2.9734692573547363 Actual: 3.137624350847544\n",
      "Prediction: 1.222303867340088 Actual: 1.3638410472397342\n",
      "Prediction: 1.3438873291015625 Actual: 1.6884763841942343\n",
      "Prediction: 1.383134126663208 Actual: 1.3503298063610123\n",
      "Prediction: 2.396585464477539 Actual: 2.0624682672770884\n",
      "Prediction: 0.9322494864463806 Actual: 1.022641733675116\n",
      "Prediction: 1.570997953414917 Actual: 1.7922893205354298\n",
      "Prediction: 0.32555603981018066 Actual: 0.0\n",
      "Prediction: 2.7406387329101562 Actual: 2.8728793655039597\n",
      "Prediction: 3.1595492362976074 Actual: 3.08869986818596\n",
      "Prediction: 2.7875924110412598 Actual: 2.937454182316864\n",
      "Prediction: 1.6914646625518799 Actual: 1.9900604524480008\n",
      "Prediction: 1.4383363723754883 Actual: 1.5165082679194366\n",
      "Prediction: 3.187680959701538 Actual: 3.300928568970799\n",
      "Prediction: 2.096662998199463 Actual: 2.172740551700977\n",
      "Prediction: 1.2511961460113525 Actual: 1.11944101772116\n",
      "Prediction: 0.9440450668334961 Actual: 1.5717864335294334\n",
      "Prediction: 0.7375269532203674 Actual: 0.4958590410264636\n",
      "Prediction: 0.17171837389469147 Actual: 0.155004788411154\n",
      "Prediction: 3.505918025970459 Actual: 3.8649768612963977\n",
      "Prediction: 1.9393198490142822 Actual: 1.8044174585321688\n",
      "Prediction: 2.597520351409912 Actual: 2.784237837142815\n",
      "Prediction: 1.2088127136230469 Actual: 1.2058569757056352\n",
      "Prediction: 2.6171116828918457 Actual: 2.823600084682192\n",
      "Prediction: 1.2636730670928955 Actual: 0.8952499802854423\n",
      "Prediction: 3.0646986961364746 Actual: 3.1122811365205387\n",
      "Prediction: 1.4942710399627686 Actual: 1.8154017176022967\n",
      "Prediction: 0.08161868155002594 Actual: 0.1005921480894177\n",
      "Prediction: 3.161980628967285 Actual: 3.065473133634235\n",
      "Prediction: 2.9925618171691895 Actual: 2.5538644982316425\n",
      "Prediction: 1.79475736618042 Actual: 1.9863780592187463\n",
      "Prediction: 0.7813356518745422 Actual: 0.9941294103867458\n",
      "Prediction: 3.267716884613037 Actual: 3.3501309740346112\n",
      "Prediction: 2.0495951175689697 Actual: 2.3116704996467785\n",
      "Prediction: 2.6556336879730225 Actual: 2.504167767054588\n",
      "Prediction: 0.4615303575992584 Actual: 0.763471998256058\n",
      "Prediction: 2.3852505683898926 Actual: 2.71222974268319\n",
      "Prediction: 0.7913320660591125 Actual: 0.9252693613945324\n",
      "Prediction: 1.822690725326538 Actual: 1.849760707133483\n",
      "Prediction: 1.494499921798706 Actual: 1.3970629516250068\n",
      "Prediction: 1.5558512210845947 Actual: 1.8889919304287464\n",
      "Prediction: 0.5850542783737183 Actual: 0.9000416924553322\n",
      "Prediction: 0.5685266852378845 Actual: 1.027727966185627\n",
      "Prediction: 0.7895930409431458 Actual: 0.7016799102374711\n",
      "Prediction: 1.3503403663635254 Actual: 1.4119815069059265\n",
      "Prediction: 2.9643421173095703 Actual: 2.977408432892682\n",
      "Prediction: 2.2404494285583496 Actual: 2.2103713279948844\n",
      "Prediction: 2.541560173034668 Actual: 2.438731252650425\n",
      "Prediction: 1.7576603889465332 Actual: 1.9212942080249984\n",
      "Prediction: 1.8769524097442627 Actual: 1.7339724542334658\n",
      "Prediction: 1.194892168045044 Actual: 1.5892697074168551\n",
      "Prediction: 1.776268720626831 Actual: 1.503416679305313\n",
      "Prediction: 2.156597137451172 Actual: 2.222002853095735\n",
      "Prediction: 3.100109100341797 Actual: 3.1062304249844512\n",
      "Prediction: 1.1807255744934082 Actual: 1.5420637396404375\n",
      "Prediction: 0.9164003729820251 Actual: 1.2523485891697117\n",
      "Prediction: 1.1589090824127197 Actual: 1.710466837709535\n",
      "Prediction: 2.690067768096924 Actual: 2.693598515909963\n",
      "Prediction: 0.8686233162879944 Actual: 0.9657009889491656\n",
      "Prediction: 1.9696292877197266 Actual: 1.86827692299816\n",
      "Prediction: 2.847099542617798 Actual: 2.806877505411242\n",
      "Prediction: 2.32814884185791 Actual: 2.342836773191855\n",
      "Prediction: 2.591879367828369 Actual: 2.583738162772638\n",
      "Prediction: 3.1308164596557617 Actual: 3.2485727923536656\n",
      "Prediction: 2.7461130619049072 Actual: 2.5844682625115074\n",
      "Prediction: 2.4982237815856934 Actual: 2.587565796370635\n",
      "Prediction: 1.2150800228118896 Actual: 1.5660204997024247\n",
      "Prediction: 0.43845152854919434 Actual: 0.8670343739276987\n",
      "Prediction: 2.3244988918304443 Actual: 1.8476004181084256\n",
      "Prediction: 0.9434617161750793 Actual: 1.1221109734183077\n",
      "Prediction: 1.5019092559814453 Actual: 1.7181817231817458\n",
      "Prediction: 1.3190357685089111 Actual: 1.1645391660958937\n",
      "Prediction: 1.8708374500274658 Actual: 1.6833300315712254\n",
      "Prediction: 1.9868743419647217 Actual: 2.018579782190191\n",
      "Prediction: 2.5755538940429688 Actual: 2.512488758731327\n",
      "Prediction: 3.121013641357422 Actual: 3.168988610106379\n",
      "Prediction: 3.2382469177246094 Actual: 3.0526409582889382\n",
      "Prediction: 0.9829316139221191 Actual: 1.1528666911541523\n",
      "Prediction: 3.303065538406372 Actual: 3.25829468502287\n",
      "Prediction: 3.377675771713257 Actual: 3.363670491095614\n",
      "Prediction: 2.2956254482269287 Actual: 2.404089819888117\n",
      "Prediction: 2.0795090198516846 Actual: 2.137692088152197\n",
      "Prediction: 2.4947681427001953 Actual: 2.427614635957672\n",
      "Prediction: 2.0106558799743652 Actual: 1.810037822647263\n",
      "Prediction: 1.6468141078948975 Actual: 1.756035494723187\n",
      "Prediction: 2.3389148712158203 Actual: 2.053147894166025\n",
      "Prediction: 1.113166332244873 Actual: 1.6014725497408242\n",
      "Prediction: 0.3386467695236206 Actual: 0.4695533233798704\n",
      "Prediction: 2.2286298274993896 Actual: 2.0046273170074884\n",
      "Prediction: 2.311465263366699 Actual: 2.2887682028383933\n",
      "Prediction: 3.326603412628174 Actual: 3.091715028356484\n",
      "Prediction: 2.230698823928833 Actual: 2.117233031215417\n",
      "Prediction: 1.1686275005340576 Actual: 1.3476334931151803\n",
      "Prediction: 1.6904776096343994 Actual: 1.5304278892477712\n",
      "Prediction: 2.796675443649292 Actual: 2.734401494419992\n",
      "Prediction: 3.654362201690674 Actual: 3.8302053754229743\n",
      "Prediction: 2.5855743885040283 Actual: 2.6394472915746228\n",
      "Prediction: 2.0923285484313965 Actual: 2.471395779180272\n",
      "Prediction: 2.1724624633789062 Actual: 2.2286086189122747\n",
      "Prediction: 0.4722583293914795 Actual: 0.6566169233161951\n",
      "Prediction: 2.251079797744751 Actual: 2.2598041504961186\n",
      "Prediction: 2.5808565616607666 Actual: 2.3327839636333105\n",
      "Prediction: 2.9504811763763428 Actual: 3.0234824828446896\n",
      "Prediction: 2.564220666885376 Actual: 2.964668230929299\n",
      "Prediction: 0.8250159025192261 Actual: 0.983576997394541\n",
      "Prediction: 1.3565711975097656 Actual: 1.465549386433812\n",
      "Prediction: 2.3387203216552734 Actual: 2.268850734169383\n",
      "Prediction: 3.4197194576263428 Actual: 3.5729453198762804\n",
      "Prediction: 0.8669231534004211 Actual: 0.6822651648416035\n",
      "Prediction: 1.741896390914917 Actual: 1.9846599185571745\n",
      "Prediction: 2.5718677043914795 Actual: 2.519724822511747\n",
      "Prediction: 0.4644729495048523 Actual: 0.5496018253589585\n",
      "Prediction: 2.899137496948242 Actual: 2.9868916209305363\n",
      "Prediction: 2.594226360321045 Actual: 2.6404761356980795\n",
      "Prediction: 1.0335378646850586 Actual: 1.4772887703973712\n",
      "Prediction: 2.0517165660858154 Actual: 1.9395846660340497\n",
      "Prediction: 1.759004831314087 Actual: 1.8298105464885008\n",
      "Prediction: 2.775871992111206 Actual: 2.6696408286087285\n",
      "Prediction: 1.7210309505462646 Actual: 1.5961281034309902\n",
      "Prediction: 2.3602662086486816 Actual: 2.278951504956563\n",
      "Prediction: 0.9835913777351379 Actual: 1.1378011102056016\n",
      "Prediction: 1.0070823431015015 Actual: 0.6768179731112823\n",
      "Prediction: 2.4227728843688965 Actual: 2.5040052870066454\n",
      "Prediction: 2.0168352127075195 Actual: 2.122638529628868\n",
      "Prediction: 2.7191312313079834 Actual: 2.977851918315743\n",
      "Prediction: 2.2174785137176514 Actual: 2.827614868021281\n",
      "Prediction: 2.746074676513672 Actual: 2.942198841728139\n",
      "Prediction: 2.1825339794158936 Actual: 2.309975847769393\n",
      "Prediction: 2.87534761428833 Actual: 2.7778858935835875\n",
      "Prediction: 2.549098491668701 Actual: 2.5244226584154354\n",
      "Prediction: 2.257493495941162 Actual: 2.135266354890094\n",
      "Prediction: 2.2857165336608887 Actual: 2.224197461212005\n",
      "Prediction: 3.1872148513793945 Actual: 3.2389317177358112\n",
      "Prediction: 2.2757182121276855 Actual: 2.230253521333785\n",
      "Prediction: 3.0179290771484375 Actual: 3.060805402033993\n",
      "Prediction: 0.8177793622016907 Actual: 1.3635615499322744\n",
      "Prediction: 3.351134777069092 Actual: 3.603507572240497\n",
      "Prediction: 2.0237433910369873 Actual: 2.1672829561454443\n",
      "Prediction: 3.1136953830718994 Actual: 3.323902960329112\n",
      "Prediction: 1.8208622932434082 Actual: 2.0165967745176614\n",
      "Prediction: 1.2918541431427002 Actual: 1.3620437691526197\n",
      "Prediction: 1.8786239624023438 Actual: 2.1156039687255843\n",
      "Prediction: 2.248447895050049 Actual: 2.465306489467062\n",
      "Prediction: 3.2924461364746094 Actual: 3.060490750087925\n",
      "Prediction: 1.9493627548217773 Actual: 1.9915084140251773\n",
      "Prediction: 0.32121461629867554 Actual: 0.264924162952827\n",
      "Prediction: 3.2692933082580566 Actual: 3.64573804877044\n",
      "Prediction: 2.9239983558654785 Actual: 2.5172289818586204\n",
      "Prediction: 1.3764808177947998 Actual: 1.5487102111350304\n",
      "Prediction: 1.226708173751831 Actual: 1.599593887728051\n",
      "Prediction: 1.5971133708953857 Actual: 1.5538733401089513\n",
      "Prediction: 2.3111510276794434 Actual: 2.595889050696416\n",
      "Prediction: 1.7792186737060547 Actual: 1.8790984603853385\n",
      "Prediction: 1.1997332572937012 Actual: 1.5066627733506968\n",
      "Prediction: 1.2382540702819824 Actual: 1.1048937876999445\n",
      "Prediction: 0.5966689586639404 Actual: 0.3413935419913523\n",
      "Prediction: 2.276782512664795 Actual: 2.4052675257641485\n",
      "Prediction: 1.894139051437378 Actual: 1.6848422066992197\n",
      "Prediction: 3.1108217239379883 Actual: 2.993502391205279\n",
      "Prediction: 3.1175076961517334 Actual: 3.4154133242434344\n",
      "Prediction: 1.3459281921386719 Actual: 1.7097013783889978\n",
      "Prediction: 1.661745309829712 Actual: 1.5386892509239083\n",
      "Prediction: 2.8680741786956787 Actual: 2.921386757069629\n",
      "Prediction: 2.3695077896118164 Actual: 2.605247445547851\n",
      "Prediction: 2.2302613258361816 Actual: 2.4400060965135784\n",
      "Prediction: 1.120267391204834 Actual: 1.42899323811113\n",
      "Prediction: 3.1144309043884277 Actual: 3.3721260428259656\n",
      "Prediction: 2.3192858695983887 Actual: 2.1516179803357813\n",
      "Prediction: 1.514357566833496 Actual: 1.5950547587554351\n",
      "Prediction: 1.3016057014465332 Actual: 1.4145556778225787\n",
      "Prediction: 3.006054639816284 Actual: 3.128858646003016\n",
      "Prediction: 2.988528251647949 Actual: 2.553439811443938\n",
      "Prediction: 3.1981215476989746 Actual: 3.1296400506375512\n",
      "Prediction: 2.748431444168091 Actual: 2.981992255406158\n",
      "Prediction: 2.9563183784484863 Actual: 2.981786874282664\n",
      "Prediction: 1.0962231159210205 Actual: 1.2010533026138683\n",
      "Prediction: 2.6893739700317383 Actual: 2.79138610847234\n",
      "Prediction: 0.41299325227737427 Actual: 0.1530318116508149\n",
      "Prediction: 0.6000497937202454 Actual: 0.6193509314675341\n",
      "Prediction: 2.207822322845459 Actual: 2.281345006080266\n",
      "Prediction: 0.6268674731254578 Actual: 0.4937411351889655\n",
      "Prediction: 2.7050578594207764 Actual: 2.966548034294946\n",
      "Prediction: 1.9222700595855713 Actual: 1.989455195588546\n",
      "Prediction: 3.78645658493042 Actual: 3.5433159148930136\n",
      "Prediction: 1.8726911544799805 Actual: 1.970600159244711\n",
      "Prediction: 1.1494221687316895 Actual: 1.3440857175872982\n",
      "Prediction: 0.703484833240509 Actual: 1.027015599936749\n",
      "Prediction: 0.5399308204650879 Actual: 0.4277633541749704\n",
      "Prediction: 2.0584065914154053 Actual: 1.9746552454467765\n",
      "Prediction: 0.993040144443512 Actual: 1.242176324159397\n",
      "Prediction: 0.37560686469078064 Actual: 0.384375395876116\n",
      "Prediction: 0.7832855582237244 Actual: 0.4474828563605549\n",
      "Prediction: 1.293806791305542 Actual: 1.7290731666537256\n",
      "Prediction: 2.137223720550537 Actual: 2.136399546240388\n",
      "Prediction: 0.35128891468048096 Actual: 0.2109791787447653\n",
      "Prediction: 0.23345249891281128 Actual: 0.33096690773874\n",
      "Prediction: 2.5990805625915527 Actual: 2.888891669272444\n",
      "Prediction: 3.1602530479431152 Actual: 3.270373860776488\n",
      "Prediction: 2.6696736812591553 Actual: 2.500113299959695\n",
      "Prediction: 1.168400764465332 Actual: 1.212880751488374\n",
      "Prediction: 2.101473093032837 Actual: 2.009298479722319\n",
      "Prediction: 1.3065416812896729 Actual: 1.543837471085622\n",
      "Prediction: 1.3459346294403076 Actual: 1.4382049683676248\n",
      "Prediction: 1.7106397151947021 Actual: 1.562359564441758\n",
      "Prediction: 1.815903902053833 Actual: 2.17490279620988\n",
      "Prediction: 2.5320372581481934 Actual: 2.3325403195354064\n",
      "Prediction: 2.6800308227539062 Actual: 2.777966932491008\n",
      "Prediction: 0.7787925004959106 Actual: 0.863545351686935\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f'Prediction: {predictions[i,0]} Actual: {y_test.iloc[i]}')\n",
    "#plt.scatter(X_test, y_test)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Compete against this model:\n",
    "- Create two more different models to compete with this model\n",
    "- Here are a few ideas of things you can change:\n",
    "   - During Dataset data engineering:\n",
    "      - You can remove features that you think do not help in the training and prediction \n",
    "      - Feature Scaling: Ensure all features are on a similar scale (as you already did with StandardScaler)\n",
    "   - During Model Definition:\n",
    "      - You can change the Model Architecture (change the type or number of layers or the number of units)\n",
    "      - You can add dropout layers to prevent overfitting\n",
    "   - During Model Compile:\n",
    "      - You can try other optimizer when compiling your model, here some optimizer samples: Adam, RMSprop, or Adagrad.\n",
    "      - Try another Loss Function\n",
    "   - During Model Training:\n",
    "      - Encrease the number of Epochs\n",
    "      - Adjust the size of your batch\n",
    "- Explain in a Markdown cell which changes are you implementing\n",
    "- Show the comparison of your model versus the original model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering\n",
    "   - Model Definition\n",
    "   - Model Compile\n",
    "   - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0890 - mae: 1.4814 - val_loss: 0.2463 - val_mae: 0.4002\n",
      "Epoch 2/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1919 - mae: 0.3387 - val_loss: 0.1413 - val_mae: 0.3094\n",
      "Epoch 3/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1234 - mae: 0.2849 - val_loss: 0.1072 - val_mae: 0.2692\n",
      "Epoch 4/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1003 - mae: 0.2552 - val_loss: 0.0852 - val_mae: 0.2363\n",
      "Epoch 5/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0767 - mae: 0.2268 - val_loss: 0.0750 - val_mae: 0.2219\n",
      "Epoch 6/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0716 - mae: 0.2151 - val_loss: 0.0670 - val_mae: 0.2063\n",
      "Epoch 7/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0604 - mae: 0.1994 - val_loss: 0.0616 - val_mae: 0.1993\n",
      "Epoch 8/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0574 - mae: 0.1932 - val_loss: 0.0611 - val_mae: 0.1969\n",
      "Epoch 9/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - mae: 0.1799 - val_loss: 0.0616 - val_mae: 0.1977\n",
      "Epoch 10/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mae: 0.1768 - val_loss: 0.0573 - val_mae: 0.1913\n",
      "Epoch 11/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mae: 0.1697 - val_loss: 0.0572 - val_mae: 0.1898\n",
      "Epoch 12/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0472 - mae: 0.1734 - val_loss: 0.0564 - val_mae: 0.1889\n",
      "Epoch 13/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0436 - mae: 0.1646 - val_loss: 0.0538 - val_mae: 0.1834\n",
      "Epoch 14/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0440 - mae: 0.1661 - val_loss: 0.0563 - val_mae: 0.1869\n",
      "Epoch 15/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0420 - mae: 0.1620 - val_loss: 0.0582 - val_mae: 0.1894\n",
      "Epoch 16/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0405 - mae: 0.1591 - val_loss: 0.0554 - val_mae: 0.1841\n",
      "Epoch 17/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0397 - mae: 0.1583 - val_loss: 0.0547 - val_mae: 0.1808\n",
      "Epoch 18/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0387 - mae: 0.1564 - val_loss: 0.0591 - val_mae: 0.1887\n",
      "Epoch 19/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0377 - mae: 0.1531 - val_loss: 0.0554 - val_mae: 0.1818\n",
      "Epoch 20/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0390 - mae: 0.1543 - val_loss: 0.0562 - val_mae: 0.1826\n",
      "Epoch 21/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1501 - val_loss: 0.0585 - val_mae: 0.1881\n",
      "Epoch 22/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mae: 0.1546 - val_loss: 0.0563 - val_mae: 0.1842\n",
      "Epoch 23/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0374 - mae: 0.1559 - val_loss: 0.0576 - val_mae: 0.1844\n",
      "Epoch 24/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0401 - mae: 0.1586 - val_loss: 0.0604 - val_mae: 0.1938\n",
      "Epoch 25/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0367 - mae: 0.1517 - val_loss: 0.0729 - val_mae: 0.2142\n",
      "Epoch 26/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0397 - mae: 0.1565 - val_loss: 0.0603 - val_mae: 0.1921\n",
      "Epoch 27/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.1470 - val_loss: 0.0559 - val_mae: 0.1857\n",
      "Epoch 28/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0361 - mae: 0.1498 - val_loss: 0.0560 - val_mae: 0.1818\n",
      "Epoch 29/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348 - mae: 0.1471 - val_loss: 0.0564 - val_mae: 0.1838\n",
      "Epoch 30/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0371 - mae: 0.1492 - val_loss: 0.0610 - val_mae: 0.1911\n",
      "Epoch 31/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0375 - mae: 0.1529 - val_loss: 0.0579 - val_mae: 0.1871\n",
      "Epoch 32/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.1440 - val_loss: 0.0626 - val_mae: 0.1941\n",
      "Epoch 33/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.1456 - val_loss: 0.0596 - val_mae: 0.1912\n",
      "Epoch 34/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0366 - mae: 0.1511 - val_loss: 0.0565 - val_mae: 0.1843\n",
      "Epoch 35/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0349 - mae: 0.1472 - val_loss: 0.0577 - val_mae: 0.1847\n",
      "Epoch 36/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0353 - mae: 0.1486 - val_loss: 0.0580 - val_mae: 0.1859\n",
      "Epoch 37/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0334 - mae: 0.1446 - val_loss: 0.0632 - val_mae: 0.1959\n",
      "Epoch 38/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0338 - mae: 0.1433 - val_loss: 0.0612 - val_mae: 0.1929\n",
      "Epoch 39/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0350 - mae: 0.1456 - val_loss: 0.0569 - val_mae: 0.1859\n",
      "Epoch 40/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0327 - mae: 0.1409 - val_loss: 0.0572 - val_mae: 0.1844\n",
      "Epoch 41/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0341 - mae: 0.1453 - val_loss: 0.0565 - val_mae: 0.1831\n",
      "Epoch 42/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0352 - mae: 0.1486 - val_loss: 0.0568 - val_mae: 0.1817\n",
      "Epoch 43/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.1437 - val_loss: 0.0574 - val_mae: 0.1826\n",
      "Epoch 44/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0313 - mae: 0.1381 - val_loss: 0.0591 - val_mae: 0.1905\n",
      "Epoch 45/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0324 - mae: 0.1405 - val_loss: 0.0567 - val_mae: 0.1831\n",
      "Epoch 46/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0304 - mae: 0.1348 - val_loss: 0.0644 - val_mae: 0.1963\n",
      "Epoch 47/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0301 - mae: 0.1356 - val_loss: 0.0589 - val_mae: 0.1875\n",
      "Epoch 48/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0320 - mae: 0.1390 - val_loss: 0.0606 - val_mae: 0.1893\n",
      "Epoch 49/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0294 - mae: 0.1345 - val_loss: 0.0573 - val_mae: 0.1843\n",
      "Epoch 50/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0312 - mae: 0.1395 - val_loss: 0.0595 - val_mae: 0.1886\n",
      "Epoch 51/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0318 - mae: 0.1394 - val_loss: 0.0592 - val_mae: 0.1903\n",
      "Epoch 52/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0298 - mae: 0.1365 - val_loss: 0.0598 - val_mae: 0.1872\n",
      "Epoch 53/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0314 - mae: 0.1396 - val_loss: 0.0598 - val_mae: 0.1891\n",
      "Epoch 54/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mae: 0.1376 - val_loss: 0.0592 - val_mae: 0.1884\n",
      "Epoch 55/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mae: 0.1309 - val_loss: 0.0628 - val_mae: 0.1944\n",
      "Epoch 56/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0299 - mae: 0.1346 - val_loss: 0.0595 - val_mae: 0.1901\n",
      "Epoch 57/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0295 - mae: 0.1348 - val_loss: 0.0589 - val_mae: 0.1862\n",
      "Epoch 58/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0283 - mae: 0.1304 - val_loss: 0.0606 - val_mae: 0.1896\n",
      "Epoch 59/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0325 - mae: 0.1409 - val_loss: 0.0597 - val_mae: 0.1885\n",
      "Epoch 60/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0279 - mae: 0.1296 - val_loss: 0.0647 - val_mae: 0.1961\n",
      "Epoch 61/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mae: 0.1307 - val_loss: 0.0604 - val_mae: 0.1888\n",
      "Epoch 62/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.1267 - val_loss: 0.0576 - val_mae: 0.1859\n",
      "Epoch 63/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0276 - mae: 0.1314 - val_loss: 0.0605 - val_mae: 0.1900\n",
      "Epoch 64/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0303 - mae: 0.1350 - val_loss: 0.0585 - val_mae: 0.1870\n",
      "Epoch 65/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0284 - mae: 0.1322 - val_loss: 0.0587 - val_mae: 0.1859\n",
      "Epoch 66/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0281 - mae: 0.1281 - val_loss: 0.0661 - val_mae: 0.1985\n",
      "Epoch 67/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0275 - mae: 0.1303 - val_loss: 0.0626 - val_mae: 0.1948\n",
      "Epoch 68/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0283 - mae: 0.1316 - val_loss: 0.0596 - val_mae: 0.1899\n",
      "Epoch 69/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0281 - mae: 0.1312 - val_loss: 0.0629 - val_mae: 0.1934\n",
      "Epoch 70/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0249 - mae: 0.1213 - val_loss: 0.0618 - val_mae: 0.1910\n",
      "Epoch 71/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1218 - val_loss: 0.0598 - val_mae: 0.1889\n",
      "Epoch 72/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1209 - val_loss: 0.0617 - val_mae: 0.1935\n",
      "Epoch 73/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.1279 - val_loss: 0.0612 - val_mae: 0.1915\n",
      "Epoch 74/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1209 - val_loss: 0.0582 - val_mae: 0.1865\n",
      "Epoch 75/75\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1202 - val_loss: 0.0601 - val_mae: 0.1898\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0616 - mae: 0.1917\n",
      "loss 0.058735113590955734\n",
      "mae 0.18684621155261993\n"
     ]
    }
   ],
   "source": [
    "dataset2 = data.drop(columns=[\"StudentID\",\"Gender\",\"Ethnicity\",\"Extracurricular\",\"Music\",\"Sports\",\"Volunteering\"])\n",
    "\n",
    "X2 = dataset2.drop(columns=['GPA'])\n",
    "y2 = dataset2['GPA'].values\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "X2_test = scaler.transform(X2_test)\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X2_train.shape[1]),\n",
    "    Dense(32, activation='relu'),    \n",
    "    Dense(16, activation='relu'),           \n",
    "    Dense(1)                  \n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse', \n",
    "    metrics=['mae']  \n",
    ")\n",
    "\n",
    "history2 = model2.fit(X2_train, y2_train, epochs=75, batch_size=15, validation_split=0.20)\n",
    "\n",
    "loss2, mae2 = model2.evaluate(X2_test, y2_test)\n",
    "print(\"loss\", loss2)\n",
    "print(\"mae\", mae2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering\n",
    "   - Model Definition\n",
    "   - Model Compile\n",
    "   - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.8105 - mae: 1.7327 - val_loss: 1.0710 - val_mae: 0.8925\n",
      "Epoch 2/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7653 - mae: 0.7098 - val_loss: 0.2700 - val_mae: 0.4182\n",
      "Epoch 3/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3019 - mae: 0.4407 - val_loss: 0.1958 - val_mae: 0.3569\n",
      "Epoch 4/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2629 - mae: 0.4070 - val_loss: 0.1619 - val_mae: 0.3255\n",
      "Epoch 5/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2386 - mae: 0.3846 - val_loss: 0.1369 - val_mae: 0.2990\n",
      "Epoch 6/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2096 - mae: 0.3639 - val_loss: 0.1200 - val_mae: 0.2787\n",
      "Epoch 7/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1797 - mae: 0.3368 - val_loss: 0.1084 - val_mae: 0.2664\n",
      "Epoch 8/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1605 - mae: 0.3166 - val_loss: 0.1026 - val_mae: 0.2593\n",
      "Epoch 9/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1588 - mae: 0.3169 - val_loss: 0.0954 - val_mae: 0.2497\n",
      "Epoch 10/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1569 - mae: 0.3176 - val_loss: 0.0915 - val_mae: 0.2444\n",
      "Epoch 11/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1655 - mae: 0.3234 - val_loss: 0.0901 - val_mae: 0.2437\n",
      "Epoch 12/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1486 - mae: 0.3065 - val_loss: 0.0854 - val_mae: 0.2364\n",
      "Epoch 13/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1358 - mae: 0.2962 - val_loss: 0.0825 - val_mae: 0.2329\n",
      "Epoch 14/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1296 - mae: 0.2880 - val_loss: 0.0798 - val_mae: 0.2278\n",
      "Epoch 15/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1296 - mae: 0.2883 - val_loss: 0.0806 - val_mae: 0.2316\n",
      "Epoch 16/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1247 - mae: 0.2811 - val_loss: 0.0754 - val_mae: 0.2211\n",
      "Epoch 17/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1297 - mae: 0.2789 - val_loss: 0.0727 - val_mae: 0.2175\n",
      "Epoch 18/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1132 - mae: 0.2702 - val_loss: 0.0748 - val_mae: 0.2216\n",
      "Epoch 19/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1180 - mae: 0.2737 - val_loss: 0.0700 - val_mae: 0.2125\n",
      "Epoch 20/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1201 - mae: 0.2749 - val_loss: 0.0674 - val_mae: 0.2087\n",
      "Epoch 21/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1000 - mae: 0.2519 - val_loss: 0.0690 - val_mae: 0.2122\n",
      "Epoch 22/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0965 - mae: 0.2490 - val_loss: 0.0663 - val_mae: 0.2072\n",
      "Epoch 23/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1012 - mae: 0.2555 - val_loss: 0.0666 - val_mae: 0.2080\n",
      "Epoch 24/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0933 - mae: 0.2480 - val_loss: 0.0619 - val_mae: 0.1988\n",
      "Epoch 25/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0974 - mae: 0.2428 - val_loss: 0.0661 - val_mae: 0.2077\n",
      "Epoch 26/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0986 - mae: 0.2515 - val_loss: 0.0617 - val_mae: 0.1983\n",
      "Epoch 27/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0913 - mae: 0.2420 - val_loss: 0.0618 - val_mae: 0.1979\n",
      "Epoch 28/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0929 - mae: 0.2402 - val_loss: 0.0646 - val_mae: 0.2053\n",
      "Epoch 29/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0899 - mae: 0.2381 - val_loss: 0.0591 - val_mae: 0.1938\n",
      "Epoch 30/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0885 - mae: 0.2379 - val_loss: 0.0584 - val_mae: 0.1945\n",
      "Epoch 31/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0838 - mae: 0.2293 - val_loss: 0.0630 - val_mae: 0.2042\n",
      "Epoch 32/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0902 - mae: 0.2422 - val_loss: 0.0617 - val_mae: 0.2011\n",
      "Epoch 33/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0736 - mae: 0.2194 - val_loss: 0.0575 - val_mae: 0.1911\n",
      "Epoch 34/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0821 - mae: 0.2286 - val_loss: 0.0604 - val_mae: 0.1986\n",
      "Epoch 35/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0800 - mae: 0.2243 - val_loss: 0.0577 - val_mae: 0.1911\n",
      "Epoch 36/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0802 - mae: 0.2216 - val_loss: 0.0550 - val_mae: 0.1854\n",
      "Epoch 37/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0709 - mae: 0.2136 - val_loss: 0.0533 - val_mae: 0.1819\n",
      "Epoch 38/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0781 - mae: 0.2194 - val_loss: 0.0542 - val_mae: 0.1846\n",
      "Epoch 39/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0710 - mae: 0.2125 - val_loss: 0.0541 - val_mae: 0.1838\n",
      "Epoch 40/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0677 - mae: 0.2078 - val_loss: 0.0541 - val_mae: 0.1838\n",
      "Epoch 41/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0724 - mae: 0.2173 - val_loss: 0.0537 - val_mae: 0.1838\n",
      "Epoch 42/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0661 - mae: 0.2067 - val_loss: 0.0546 - val_mae: 0.1861\n",
      "Epoch 43/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0703 - mae: 0.2100 - val_loss: 0.0542 - val_mae: 0.1842\n",
      "Epoch 44/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0646 - mae: 0.2022 - val_loss: 0.0531 - val_mae: 0.1823\n",
      "Epoch 45/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.2050 - val_loss: 0.0529 - val_mae: 0.1809\n",
      "Epoch 46/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0654 - mae: 0.2033 - val_loss: 0.0536 - val_mae: 0.1833\n",
      "Epoch 47/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0613 - mae: 0.1950 - val_loss: 0.0515 - val_mae: 0.1771\n",
      "Epoch 48/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0606 - mae: 0.1951 - val_loss: 0.0551 - val_mae: 0.1875\n",
      "Epoch 49/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0602 - mae: 0.1930 - val_loss: 0.0554 - val_mae: 0.1878\n",
      "Epoch 50/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0600 - mae: 0.1932 - val_loss: 0.0525 - val_mae: 0.1781\n",
      "Epoch 51/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0618 - mae: 0.1957 - val_loss: 0.0509 - val_mae: 0.1761\n",
      "Epoch 52/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0609 - mae: 0.1918 - val_loss: 0.0518 - val_mae: 0.1790\n",
      "Epoch 53/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657 - mae: 0.2036 - val_loss: 0.0573 - val_mae: 0.1919\n",
      "Epoch 54/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0614 - mae: 0.1990 - val_loss: 0.0551 - val_mae: 0.1869\n",
      "Epoch 55/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0600 - mae: 0.1950 - val_loss: 0.0522 - val_mae: 0.1811\n",
      "Epoch 56/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0583 - mae: 0.1881 - val_loss: 0.0490 - val_mae: 0.1728\n",
      "Epoch 57/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0615 - mae: 0.1974 - val_loss: 0.0515 - val_mae: 0.1783\n",
      "Epoch 58/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0581 - mae: 0.1906 - val_loss: 0.0501 - val_mae: 0.1745\n",
      "Epoch 59/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0522 - mae: 0.1789 - val_loss: 0.0499 - val_mae: 0.1735\n",
      "Epoch 60/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0595 - mae: 0.1945 - val_loss: 0.0499 - val_mae: 0.1741\n",
      "Epoch 61/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0577 - mae: 0.1882 - val_loss: 0.0500 - val_mae: 0.1735\n",
      "Epoch 62/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.1856 - val_loss: 0.0480 - val_mae: 0.1705\n",
      "Epoch 63/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0548 - mae: 0.1857 - val_loss: 0.0507 - val_mae: 0.1758\n",
      "Epoch 64/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0604 - mae: 0.1939 - val_loss: 0.0483 - val_mae: 0.1708\n",
      "Epoch 65/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0549 - mae: 0.1876 - val_loss: 0.0500 - val_mae: 0.1735\n",
      "Epoch 66/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0615 - mae: 0.1940 - val_loss: 0.0498 - val_mae: 0.1725\n",
      "Epoch 67/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0590 - mae: 0.1922 - val_loss: 0.0516 - val_mae: 0.1799\n",
      "Epoch 68/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0550 - mae: 0.1827 - val_loss: 0.0491 - val_mae: 0.1703\n",
      "Epoch 69/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.1753 - val_loss: 0.0489 - val_mae: 0.1718\n",
      "Epoch 70/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0594 - mae: 0.1906 - val_loss: 0.0531 - val_mae: 0.1805\n",
      "Epoch 71/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.1800 - val_loss: 0.0526 - val_mae: 0.1748\n",
      "Epoch 72/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.1831 - val_loss: 0.0523 - val_mae: 0.1800\n",
      "Epoch 73/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0506 - mae: 0.1781 - val_loss: 0.0490 - val_mae: 0.1699\n",
      "Epoch 74/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0563 - mae: 0.1862 - val_loss: 0.0492 - val_mae: 0.1707\n",
      "Epoch 75/75\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0544 - mae: 0.1833 - val_loss: 0.0515 - val_mae: 0.1775\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0547 - mae: 0.1805\n",
      "loss 0.051322776824235916\n",
      "mae 0.17609354853630066\n"
     ]
    }
   ],
   "source": [
    "dataset3 = data.drop(columns=[\"StudentID\",\"Gender\",\"Ethnicity\",\"Extracurricular\",\"Music\",\"Sports\",\"Volunteering\"])\n",
    "\n",
    "X3 = dataset3.drop(columns=['GPA'])\n",
    "y3 = dataset3['GPA'].values\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X3_train = scaler.fit_transform(X3_train)\n",
    "X3_test = scaler.transform(X3_test)\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X3_train.shape[1]),\n",
    "    Dropout(0.25),    \n",
    "    Dense(16, activation='relu'),           \n",
    "    Dense(1)                  \n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse', \n",
    "    metrics=['mae']  \n",
    ")\n",
    "\n",
    "history3 = model3.fit(X3_train, y3_train, epochs=75, batch_size=30, validation_split=0.25)\n",
    "\n",
    "loss3, mae3 = model3.evaluate(X3_test, y3_test)\n",
    "print(\"loss\", loss3)\n",
    "print(\"mae\", mae3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "      y_test_real  Predicción Model1  Predicción Model2  Predicción Model3\n",
      "1004     1.427724           1.385005           1.386592           1.406456\n",
      "196      3.117354           2.952120           3.164166           3.000356\n",
      "2342     2.037769           1.843804           2.198625           2.161036\n",
      "1708     3.548521           3.620174           3.758330           3.601975\n",
      "435      0.248977           0.316628           0.497398           0.466134\n"
     ]
    }
   ],
   "source": [
    "X_test_sample = X_test[:5]\n",
    "y_test_sample = y_test[:5]\n",
    "\n",
    "X_test_sample2 = X2_test[:5]\n",
    "X_test_sample3 = X3_test[:5]\n",
    "\n",
    "\n",
    "predictions_model = model.predict(X_test_sample)\n",
    "predictions_model2 = model2.predict(X_test_sample2)\n",
    "predictions_model3 = model3.predict(X_test_sample3)\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame({\n",
    "    'y_test_real': y_test_sample,\n",
    "    'Predicción Model1': predictions_model.flatten(),\n",
    "    'Predicción Model2': predictions_model2.flatten(),\n",
    "    'Predicción Model3': predictions_model3.flatten()\n",
    "})\n",
    "\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
